"""
Question Queue Models - Phase 6 Stage 4

Intelligent question queue system for contextual task clarification.

Design Decisions:
1. Database-persisted (survives restarts, enables analytics)
2. Hybrid priority scoring (importance × impact × recency × engagement)
3. Task + semantic clustering for batching
4. Smart timing (defer during flow, show on idle)
5. Full lifecycle tracking (queued → ready → shown → answered/dismissed/snoozed)
6. Answer validation with suggestions (user control + learning)
7. Outcome tracking (did answer actually help?)

Lifecycle States:
- queued: Just created, not ready to show
- ready: Ready to be shown (passed batching/timing logic)
- shown: Currently displayed to user
- answered: User provided answer
- dismissed: User explicitly dismissed
- snoozed: User postponed (show later)

Priority Scoring Formula:
priority_score = importance_weight × field_impact × recency_factor × engagement_rate
"""

from sqlalchemy import Column, Integer, String, Text, Float, Boolean, DateTime, JSON, Index
from sqlalchemy.orm import relationship
from datetime import datetime
from db.database import Base


# ============================================================================
# QUESTION QUEUE MODEL
# ============================================================================

class QuestionQueue(Base):
    """
    Represents a queued question for user clarification.

    Questions are generated by the task synthesizer when context gaps are detected.
    They are prioritized, batched, and shown to users at optimal times.
    """

    __tablename__ = "question_queue"

    # Primary key
    id = Column(Integer, primary_key=True)

    # Foreign keys
    task_id = Column(String, nullable=False, index=True)  # FK enforced by application

    # Question content
    field_name = Column(String(100), nullable=False, index=True)  # e.g., "priority", "assignee"
    question = Column(Text, nullable=False)
    suggested_answer = Column(Text, nullable=True)  # AI's best guess

    # Importance (static, from synthesizer)
    importance = Column(String(20), nullable=False, index=True)  # "HIGH", "MEDIUM", "LOW"
    confidence = Column(Float, nullable=False)  # 0.0-1.0 (AI confidence in suggested_answer)

    # Priority (dynamic, calculated)
    priority_score = Column(Float, nullable=False, index=True)  # Calculated score for ordering
    field_impact = Column(Float, nullable=False)  # How much this field affects task quality (0.0-1.0)
    recency_factor = Column(Float, nullable=False)  # Time decay factor (1.0 = new, 0.0 = old)

    # Batching
    batch_id = Column(String, nullable=True, index=True)  # Group related questions
    semantic_cluster = Column(String, nullable=True)  # Semantic grouping (e.g., "priority_planning")

    # Lifecycle
    status = Column(
        String(20),
        nullable=False,
        default="queued",
        index=True
    )  # queued, ready, shown, answered, dismissed, snoozed
    created_at = Column(DateTime, default=datetime.utcnow, nullable=False, index=True)
    ready_at = Column(DateTime, nullable=True)  # When it became ready to show
    shown_at = Column(DateTime, nullable=True)  # When shown to user
    answered_at = Column(DateTime, nullable=True)  # When answered
    snoozed_until = Column(DateTime, nullable=True)  # If snoozed, show after this time

    # Answer
    answer = Column(Text, nullable=True)  # User's answer
    answer_source = Column(String(20), nullable=True)  # "user_input", "selected_suggestion", "dismissed"
    answer_applied = Column(Boolean, default=False)  # Was answer applied to task?

    # User feedback
    user_feedback = Column(String(20), nullable=True)  # "helpful", "not_helpful", null
    user_feedback_comment = Column(Text, nullable=True)

    # Outcome tracking (learning signal)
    outcome_impact = Column(String(20), nullable=True)  # "high_impact", "medium_impact", "low_impact", "no_impact"
    outcome_tracked = Column(Boolean, default=False)  # Was outcome evaluated?
    outcome_notes = Column(Text, nullable=True)

    # Context
    task_context = Column(JSON, nullable=True)  # Snapshot of task state when question created
    related_questions = Column(JSON, default=list)  # IDs of related questions in same batch

    # Indexes for common queries
    __table_args__ = (
        Index('idx_queue_task_status', 'task_id', 'status'),
        Index('idx_queue_priority', 'status', 'priority_score'),
        Index('idx_queue_batch', 'batch_id', 'created_at'),
        Index('idx_queue_ready', 'status', 'ready_at'),
    )


# ============================================================================
# QUESTION BATCH MODEL
# ============================================================================

class QuestionBatch(Base):
    """
    Represents a batch of related questions to show together.

    Batches reduce user interruption by grouping related questions.
    """

    __tablename__ = "question_batches"

    # Primary key
    id = Column(String, primary_key=True)  # UUID

    # Batch metadata
    created_at = Column(DateTime, default=datetime.utcnow, nullable=False)
    batch_type = Column(String(50), nullable=False)  # "task_specific", "semantic_cluster", "time_based"
    semantic_cluster = Column(String, nullable=True)  # If semantic clustering

    # Questions in batch
    question_count = Column(Integer, nullable=False, default=0)
    question_ids = Column(JSON, default=list)  # List of QuestionQueue IDs

    # Task association
    task_ids = Column(JSON, default=list)  # Tasks involved (may be multiple for semantic batches)

    # Display
    shown_to_user = Column(Boolean, default=False)
    shown_at = Column(DateTime, nullable=True)
    completed = Column(Boolean, default=False)
    completed_at = Column(DateTime, nullable=True)

    # Statistics
    answered_count = Column(Integer, default=0)
    dismissed_count = Column(Integer, default=0)
    snoozed_count = Column(Integer, default=0)


# ============================================================================
# USER ENGAGEMENT METRICS
# ============================================================================

class QuestionEngagementMetrics(Base):
    """
    Tracks user engagement with questions for adaptive learning.

    Helps system learn:
    - Which questions users find helpful vs annoying
    - Which fields users actually care about
    - Optimal timing and batching strategies
    """

    __tablename__ = "question_engagement_metrics"

    # Primary key
    id = Column(Integer, primary_key=True)

    # Aggregation period
    period_start = Column(DateTime, nullable=False, index=True)
    period_end = Column(DateTime, nullable=False)
    period_type = Column(String(20), nullable=False)  # "daily", "weekly", "all_time"

    # Question statistics
    total_questions = Column(Integer, default=0)
    questions_shown = Column(Integer, default=0)
    questions_answered = Column(Integer, default=0)
    questions_dismissed = Column(Integer, default=0)
    questions_snoozed = Column(Integer, default=0)

    # Field-level metrics
    field_metrics = Column(JSON, default=dict)
    # Example: {"priority": {"shown": 10, "answered": 8, "helpful": 6}, "assignee": {...}}

    # Timing metrics
    avg_time_to_answer = Column(Float, nullable=True)  # Seconds
    avg_batch_size = Column(Float, nullable=True)
    optimal_timing = Column(String(50), nullable=True)  # "immediate", "batched", "deferred"

    # Quality metrics
    helpful_rate = Column(Float, nullable=True)  # % marked helpful
    answer_applied_rate = Column(Float, nullable=True)  # % answers actually used
    high_impact_rate = Column(Float, nullable=True)  # % with high outcome impact


# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

def calculate_priority_score(
    importance: str,
    field_impact: float,
    recency_factor: float,
    engagement_rate: float = 0.5
) -> float:
    """
    Calculate priority score for question ordering.

    Formula: priority_score = importance_weight × field_impact × recency_factor × engagement_rate

    Args:
        importance: "HIGH", "MEDIUM", "LOW"
        field_impact: 0.0-1.0 (how much this field affects task quality)
        recency_factor: 0.0-1.0 (time decay, 1.0 = new)
        engagement_rate: 0.0-1.0 (historical user engagement with this field)

    Returns:
        Priority score (higher = more important)
    """
    importance_weights = {
        "HIGH": 10.0,
        "MEDIUM": 5.0,
        "LOW": 1.0
    }

    weight = importance_weights.get(importance, 1.0)
    score = weight * field_impact * recency_factor * engagement_rate

    return round(score, 2)


def get_field_impact(field_name: str) -> float:
    """
    Get impact weight for a field (how much it affects task quality).

    Higher impact = more important to ask about.

    Returns:
        Impact score 0.0-1.0
    """
    field_impacts = {
        # Critical fields
        "priority": 1.0,
        "due_date": 0.9,
        "assignee": 0.9,

        # Important fields
        "effort_estimate": 0.8,
        "project": 0.7,
        "dependencies": 0.7,

        # Moderate fields
        "tags": 0.5,
        "notes": 0.4,

        # Low impact
        "color": 0.2,
        "icon": 0.1
    }

    return field_impacts.get(field_name, 0.5)  # Default: medium impact


def calculate_recency_factor(created_at: datetime) -> float:
    """
    Calculate time decay factor (questions get less important over time).

    Returns:
        Recency factor 0.0-1.0 (1.0 = just created, decays over time)
    """
    from datetime import datetime, timedelta

    age = datetime.utcnow() - created_at
    days = age.total_seconds() / 86400

    # Exponential decay: 1.0 at 0 days, 0.5 at 7 days, 0.1 at 30 days
    factor = max(0.1, min(1.0, 1.0 - (days / 30)))

    return round(factor, 2)


def should_batch_together(q1: QuestionQueue, q2: QuestionQueue) -> bool:
    """
    Determine if two questions should be batched together.

    Batching criteria:
    1. Same task (always batch)
    2. Same semantic cluster (batch if close in time)
    3. Related fields (e.g., priority + effort_estimate)

    Args:
        q1: First question
        q2: Second question

    Returns:
        True if should batch together
    """
    # Same task: always batch
    if q1.task_id == q2.task_id:
        return True

    # Same semantic cluster within 1 hour
    if q1.semantic_cluster and q1.semantic_cluster == q2.semantic_cluster:
        time_diff = abs((q1.created_at - q2.created_at).total_seconds())
        if time_diff < 3600:  # 1 hour
            return True

    # Related fields (priority planning)
    priority_fields = {"priority", "effort_estimate", "due_date"}
    if q1.field_name in priority_fields and q2.field_name in priority_fields:
        return True

    return False
