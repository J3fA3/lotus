#!/bin/bash

# AI Task Inference Backend Startup Script
# Run this in the dev container

set -e

echo "ğŸš€ Starting AI Task Inference Backend"
echo ""

# Navigate to backend directory
cd "$(dirname "$0")/backend"

# Check if venv exists
if [ ! -d "venv" ]; then
    echo "ğŸ“¦ Creating virtual environment..."
    python3 -m venv venv
    echo "âœ… Virtual environment created"
fi

# Activate virtual environment
echo "ğŸ”§ Activating virtual environment..."
source venv/bin/activate

# Install dependencies
echo "ğŸ“¥ Installing dependencies..."
pip install -q -r requirements.txt

echo ""
echo "âœ… Setup complete!"
echo ""
echo "ğŸ¤– AI Model: qwen2.5:7b-instruct"
echo "ğŸ”— Ollama URL: http://host.docker.internal:11434"
echo "ğŸ“¡ Backend URL: http://localhost:8000"
echo "ğŸ“š API Docs: http://localhost:8000/docs"
echo ""
echo "âš ï¸  Make sure Ollama is running on your Mac:"
echo "   Terminal on Mac: ollama serve"
echo ""
echo "ğŸš€ Starting FastAPI server..."
echo ""

# Start the server
python main.py
